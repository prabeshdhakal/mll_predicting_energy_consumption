{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beepy import beep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import catboost\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error as MSLE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_catboost_pool(X, y, categorical_features):\n",
    "    \"\"\"Returns Catboost Pool with categorical encoding.\"\"\"\n",
    "\n",
    "    X_to_encode = X[categorical_features].astype('str')\n",
    "    X_no_encoding_reqd = X[list(set(X) - set(categorical_features))]\n",
    "\n",
    "    X_encoded = pd.merge(X_no_encoding_reqd, X_to_encode, left_index=True, right_index=True)\n",
    "\n",
    "    return Pool(X_encoded, y, cat_features=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importance(model, method='catboost'):\n",
    "    \"\"\"Single wrapper to show feature importance\"\"\"\n",
    "    \n",
    "    if method == 'lgbm':\n",
    "        feat_imp = {}\n",
    "        for i in range(len(model.feature_importance())):\n",
    "            feat_imp[ (model.feature_name())[i]] = (model.feature_importance())[i]\n",
    "        result_dict = {k: v for k, v in sorted(feat_imp.items(), key=lambda item: item[1], reverse=True)}\n",
    "        result = pd.DataFrame(result_dict.items(), columns=[\"Feature Id\", \"Importances\"])\n",
    "    \n",
    "    elif method == 'catboost':\n",
    "        result = model.get_feature_importance(prettified=True, verbose=True)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site_id has been removed form the list below\n",
    "cat_features = ['building_id', 'meter', 'primary_use',\n",
    "                'air_temperature_was_missing',\n",
    "                'cloud_coverage_was_missing', 'dew_temperature_was_missing',\n",
    "                'precip_depth_1_hr_was_missing', 'sea_level_pressure_was_missing',\n",
    "                'wind_direction_was_missing', 'wind_speed_was_missing',\n",
    "                'day_of_month', 'day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_id_train = \"/data/site_id/train/\"\n",
    "site_id_test = \"/data/site_id/test/\"\n",
    "site_id_feat_imp = \"/data/site_id/imp_features/\"\n",
    "site_id_models = \"/data/site_id/final_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting training with: site_0\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.1483485\ttest: 0.1479913\tbest: 0.1479913 (0)\ttotal: 330ms\tremaining: 2m 27s\n",
      "100:\tlearn: 0.1097533\ttest: 0.1080915\tbest: 0.1080915 (100)\ttotal: 26.1s\tremaining: 1m 30s\n",
      "200:\tlearn: 0.0963933\ttest: 0.0943070\tbest: 0.0943070 (200)\ttotal: 51.9s\tremaining: 1m 4s\n",
      "300:\tlearn: 0.0907607\ttest: 0.0880459\tbest: 0.0880459 (300)\ttotal: 1m 23s\tremaining: 41.5s\n",
      "400:\tlearn: 0.0884386\ttest: 0.0851277\tbest: 0.0851277 (399)\ttotal: 1m 52s\tremaining: 13.8s\n",
      "449:\tlearn: 0.0884377\ttest: 0.0851276\tbest: 0.0851272 (401)\ttotal: 1m 57s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.08512722689\n",
      "bestIteration = 401\n",
      "\n",
      "Shrink model to first 402 iterations.\n",
      " - model fitted ...\n",
      " - it took 2.012193481127421 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_0 \n",
      "\n",
      "Attempting training with: site_1\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.2827783\ttest: 0.2817872\tbest: 0.2817872 (0)\ttotal: 295ms\tremaining: 2m 27s\n",
      "100:\tlearn: 0.1818982\ttest: 0.1799239\tbest: 0.1799239 (100)\ttotal: 15.4s\tremaining: 1m 1s\n",
      "200:\tlearn: 0.1444348\ttest: 0.1415611\tbest: 0.1415611 (200)\ttotal: 35.5s\tremaining: 52.8s\n",
      "300:\tlearn: 0.1293463\ttest: 0.1255436\tbest: 0.1255436 (300)\ttotal: 53.8s\tremaining: 35.6s\n",
      "400:\tlearn: 0.1280713\ttest: 0.1233427\tbest: 0.1233425 (347)\ttotal: 1m 3s\tremaining: 15.6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.1233424943\n",
      "bestIteration = 347\n",
      "\n",
      "Shrink model to first 348 iterations.\n",
      " - model fitted ...\n",
      " - it took 1.1236347675323486 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_1 \n",
      "\n",
      "Attempting training with: site_2\n",
      " - imp features selected ... reading training files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\prabesh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "c:\\users\\prabesh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (12,13,14,15,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.3543204\ttest: 0.3527032\tbest: 0.3527032 (0)\ttotal: 1.38s\tremaining: 8m\n",
      "100:\tlearn: 0.2243199\ttest: 0.2214579\tbest: 0.2214579 (100)\ttotal: 54.8s\tremaining: 2m 15s\n",
      "200:\tlearn: 0.1808766\ttest: 0.1777062\tbest: 0.1777062 (200)\ttotal: 1m 50s\tremaining: 1m 21s\n",
      "300:\tlearn: 0.1670328\ttest: 0.1613792\tbest: 0.1613792 (299)\ttotal: 2m 45s\tremaining: 27s\n",
      "349:\tlearn: 0.1670275\ttest: 0.1613849\tbest: 0.1613777 (302)\ttotal: 2m 59s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1613776579\n",
      "bestIteration = 302\n",
      "\n",
      "Shrink model to first 303 iterations.\n",
      " - model fitted ...\n",
      " - it took 3.0413495659828187 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_2 \n",
      "\n",
      "Attempting training with: site_3\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.1151580\ttest: 0.1148931\tbest: 0.1148931 (0)\ttotal: 1.11s\tremaining: 8m 17s\n",
      "100:\tlearn: 0.0481933\ttest: 0.0475571\tbest: 0.0475571 (100)\ttotal: 1m 9s\tremaining: 4m 1s\n",
      "200:\tlearn: 0.0323332\ttest: 0.0317651\tbest: 0.0317651 (200)\ttotal: 2m 23s\tremaining: 2m 57s\n",
      "300:\tlearn: 0.0270210\ttest: 0.0264994\tbest: 0.0264994 (300)\ttotal: 3m 36s\tremaining: 1m 47s\n",
      "400:\tlearn: 0.0250699\ttest: 0.0243513\tbest: 0.0243513 (400)\ttotal: 4m 43s\tremaining: 34.7s\n",
      "449:\tlearn: 0.0250694\ttest: 0.0243509\tbest: 0.0243506 (405)\ttotal: 4m 58s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.02435058835\n",
      "bestIteration = 405\n",
      "\n",
      "Shrink model to first 406 iterations.\n",
      " - model fitted ...\n",
      " - it took 5.089732360839844 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_3 \n",
      "\n",
      "Attempting training with: site_4\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.2144857\ttest: 0.2140785\tbest: 0.2140785 (0)\ttotal: 489ms\tremaining: 4m 28s\n",
      "100:\tlearn: 0.0724846\ttest: 0.0724404\tbest: 0.0724404 (100)\ttotal: 37.9s\tremaining: 2m 48s\n",
      "200:\tlearn: 0.0335094\ttest: 0.0333595\tbest: 0.0333595 (200)\ttotal: 1m 16s\tremaining: 2m 12s\n",
      "300:\tlearn: 0.0203935\ttest: 0.0201624\tbest: 0.0201624 (300)\ttotal: 1m 56s\tremaining: 1m 36s\n",
      "400:\tlearn: 0.0155497\ttest: 0.0151802\tbest: 0.0151802 (400)\ttotal: 2m 34s\tremaining: 57.3s\n",
      "500:\tlearn: 0.0146606\ttest: 0.0141662\tbest: 0.0141655 (454)\ttotal: 2m 55s\tremaining: 17.2s\n",
      "549:\tlearn: 0.0146603\ttest: 0.0141664\tbest: 0.0141655 (454)\ttotal: 3m 1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.01416549216\n",
      "bestIteration = 454\n",
      "\n",
      "Shrink model to first 455 iterations.\n",
      " - model fitted ...\n",
      " - it took 3.0891860564549765 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_4 \n",
      "\n",
      "Attempting training with: site_5\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.1652938\ttest: 0.1652655\tbest: 0.1652655 (0)\ttotal: 488ms\tremaining: 3m 14s\n",
      "100:\tlearn: 0.0910524\ttest: 0.0900121\tbest: 0.0900121 (100)\ttotal: 24.3s\tremaining: 1m 11s\n",
      "200:\tlearn: 0.0726292\ttest: 0.0712812\tbest: 0.0712812 (200)\ttotal: 53.8s\tremaining: 53.2s\n",
      "300:\tlearn: 0.0678430\ttest: 0.0658633\tbest: 0.0658632 (297)\ttotal: 1m 17s\tremaining: 25.4s\n",
      "399:\tlearn: 0.0678338\ttest: 0.0658566\tbest: 0.0658566 (396)\ttotal: 1m 27s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.06585658223\n",
      "bestIteration = 396\n",
      "\n",
      "Shrink model to first 397 iterations.\n",
      " - model fitted ...\n",
      " - it took 1.4774245381355287 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_5 \n",
      "\n",
      "Attempting training with: site_6\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.5554507\ttest: 0.5553272\tbest: 0.5553272 (0)\ttotal: 545ms\tremaining: 11m 47s\n",
      "100:\tlearn: 0.2740886\ttest: 0.2561743\tbest: 0.2561689 (97)\ttotal: 33.7s\tremaining: 6m 40s\n",
      "200:\tlearn: 0.2739700\ttest: 0.2560337\tbest: 0.2560285 (172)\ttotal: 44.8s\tremaining: 4m 5s\n",
      "300:\tlearn: 0.2736936\ttest: 0.2558311\tbest: 0.2558311 (300)\ttotal: 56.8s\tremaining: 3m 8s\n",
      "400:\tlearn: 0.2730807\ttest: 0.2552697\tbest: 0.2552686 (399)\ttotal: 1m 9s\tremaining: 2m 36s\n",
      "500:\tlearn: 0.2729551\ttest: 0.2551626\tbest: 0.2551440 (471)\ttotal: 1m 21s\tremaining: 2m 10s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.2551439915\n",
      "bestIteration = 471\n",
      "\n",
      "Shrink model to first 472 iterations.\n",
      " - model fitted ...\n",
      " - it took 1.5151887694994608 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_6 \n",
      "\n",
      "Attempting training with: site_7\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.8771002\ttest: 0.8724670\tbest: 0.8724670 (0)\ttotal: 138ms\tremaining: 20.6s\n",
      "100:\tlearn: 0.3949377\ttest: 0.3887417\tbest: 0.3887417 (100)\ttotal: 11s\tremaining: 5.34s\n",
      "149:\tlearn: 0.3740003\ttest: 0.3676860\tbest: 0.3676860 (149)\ttotal: 16.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3676860245\n",
      "bestIteration = 149\n",
      "\n",
      " - model fitted ...\n",
      " - it took 0.27808621724446614 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_7 \n",
      "\n",
      "Attempting training with: site_8\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.2877610\ttest: 0.2871208\tbest: 0.2871208 (0)\ttotal: 256ms\tremaining: 1m 29s\n",
      "100:\tlearn: 0.1225189\ttest: 0.1213175\tbest: 0.1213175 (100)\ttotal: 16.1s\tremaining: 39.8s\n",
      "200:\tlearn: 0.0785224\ttest: 0.0773278\tbest: 0.0773278 (200)\ttotal: 32.2s\tremaining: 23.9s\n",
      "300:\tlearn: 0.0627910\ttest: 0.0616011\tbest: 0.0616011 (300)\ttotal: 46.9s\tremaining: 7.63s\n",
      "349:\tlearn: 0.0622854\ttest: 0.0609394\tbest: 0.0609385 (320)\ttotal: 51.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.06093847945\n",
      "bestIteration = 320\n",
      "\n",
      "Shrink model to first 321 iterations.\n",
      " - model fitted ...\n",
      " - it took 0.8785751461982727 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_8 \n",
      "\n",
      "Attempting training with: site_9\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.2644372\ttest: 0.2645003\tbest: 0.2645003 (0)\ttotal: 1.4s\tremaining: 9m 19s\n",
      "100:\tlearn: 0.2046792\ttest: 0.2037423\tbest: 0.2037423 (100)\ttotal: 1m 23s\tremaining: 4m 7s\n",
      "200:\tlearn: 0.1836413\ttest: 0.1816636\tbest: 0.1816636 (200)\ttotal: 3m 14s\tremaining: 3m 12s\n",
      "300:\tlearn: 0.1640699\ttest: 0.1597782\tbest: 0.1597782 (300)\ttotal: 4m 54s\tremaining: 1m 36s\n",
      "399:\tlearn: 0.1617647\ttest: 0.1566285\tbest: 0.1566279 (339)\ttotal: 5m 39s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1566278666\n",
      "bestIteration = 339\n",
      "\n",
      "Shrink model to first 340 iterations.\n",
      " - model fitted ...\n",
      " - it took 5.755021202564239 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_9 \n",
      "\n",
      "Attempting training with: site_10\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.5266087\ttest: 0.5320138\tbest: 0.5320138 (0)\ttotal: 180ms\tremaining: 26.8s\n",
      "100:\tlearn: 0.2394758\ttest: 0.2402831\tbest: 0.2402831 (100)\ttotal: 13.5s\tremaining: 6.57s\n",
      "149:\tlearn: 0.2350997\ttest: 0.2356306\tbest: 0.2355924 (139)\ttotal: 19.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2355923617\n",
      "bestIteration = 139\n",
      "\n",
      "Shrink model to first 140 iterations.\n",
      " - model fitted ...\n",
      " - it took 0.33455677429835 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_10 \n",
      "\n",
      "Attempting training with: site_11\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.6302247\ttest: 0.6379354\tbest: 0.6379354 (0)\ttotal: 87.4ms\tremaining: 30.5s\n",
      "100:\tlearn: 0.1625352\ttest: 0.1511733\tbest: 0.1511733 (100)\ttotal: 7.85s\tremaining: 19.4s\n",
      "200:\tlearn: 0.1568427\ttest: 0.1409922\tbest: 0.1409825 (190)\ttotal: 11s\tremaining: 8.12s\n",
      "300:\tlearn: 0.1566675\ttest: 0.1409431\tbest: 0.1409307 (299)\ttotal: 13s\tremaining: 2.11s\n",
      "349:\tlearn: 0.1565687\ttest: 0.1409223\tbest: 0.1409223 (349)\ttotal: 13.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1409223067\n",
      "bestIteration = 349\n",
      "\n",
      " - model fitted ...\n",
      " - it took 0.23938809633255004 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_11 \n",
      "\n",
      "Attempting training with: site_12\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.0818196\ttest: 0.0814761\tbest: 0.0814761 (0)\ttotal: 133ms\tremaining: 1m 12s\n",
      "100:\tlearn: 0.0343721\ttest: 0.0335510\tbest: 0.0335510 (100)\ttotal: 12.4s\tremaining: 55.1s\n",
      "200:\tlearn: 0.0243371\ttest: 0.0233738\tbest: 0.0233738 (200)\ttotal: 24.1s\tremaining: 41.9s\n",
      "300:\tlearn: 0.0215599\ttest: 0.0204476\tbest: 0.0204476 (300)\ttotal: 35.3s\tremaining: 29.2s\n",
      "400:\tlearn: 0.0204965\ttest: 0.0192776\tbest: 0.0192776 (400)\ttotal: 46.4s\tremaining: 17.2s\n",
      "500:\tlearn: 0.0202752\ttest: 0.0189535\tbest: 0.0189535 (480)\ttotal: 54s\tremaining: 5.28s\n",
      "549:\tlearn: 0.0202746\ttest: 0.0189534\tbest: 0.0189534 (523)\ttotal: 56.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.01895341222\n",
      "bestIteration = 523\n",
      "\n",
      "Shrink model to first 524 iterations.\n",
      " - model fitted ...\n",
      " - it took 0.9584441304206848 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_12 \n",
      "\n",
      "Attempting training with: site_13\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.4585900\ttest: 0.4585623\tbest: 0.4585623 (0)\ttotal: 1.82s\tremaining: 10m 36s\n",
      "100:\tlearn: 0.2066563\ttest: 0.2030644\tbest: 0.2030644 (100)\ttotal: 2m 21s\tremaining: 5m 47s\n",
      "200:\tlearn: 0.2033619\ttest: 0.1982636\tbest: 0.1982599 (190)\ttotal: 3m 16s\tremaining: 2m 25s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.1982599327\n",
      "bestIteration = 190\n",
      "\n",
      "Shrink model to first 191 iterations.\n",
      " - model fitted ...\n",
      " - it took 4.053399260838827 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_13 \n",
      "\n",
      "Attempting training with: site_14\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.4431766\ttest: 0.4412267\tbest: 0.4412267 (0)\ttotal: 2.1s\tremaining: 6m 58s\n",
      "100:\tlearn: 0.3218016\ttest: 0.3154335\tbest: 0.3154335 (100)\ttotal: 2m 10s\tremaining: 2m 7s\n",
      "199:\tlearn: 0.3102796\ttest: 0.3012927\tbest: 0.3012826 (139)\ttotal: 3m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3012826314\n",
      "bestIteration = 139\n",
      "\n",
      "Shrink model to first 140 iterations.\n",
      " - model fitted ...\n",
      " - it took 3.5041880369186402 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_14 \n",
      "\n",
      "Attempting training with: site_15\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.2518745\ttest: 0.2508717\tbest: 0.2508717 (0)\ttotal: 1.28s\tremaining: 8m 31s\n",
      "100:\tlearn: 0.1500587\ttest: 0.1489578\tbest: 0.1489578 (100)\ttotal: 1m 16s\tremaining: 3m 46s\n",
      "200:\tlearn: 0.1143270\ttest: 0.1131834\tbest: 0.1131834 (200)\ttotal: 2m 48s\tremaining: 2m 46s\n",
      "300:\tlearn: 0.1012628\ttest: 0.0998276\tbest: 0.0998276 (300)\ttotal: 4m 33s\tremaining: 1m 29s\n",
      "399:\tlearn: 0.0995254\ttest: 0.0977067\tbest: 0.0977042 (341)\ttotal: 5m 52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.09770423286\n",
      "bestIteration = 341\n",
      "\n",
      "Shrink model to first 342 iterations.\n",
      " - model fitted ...\n",
      " - it took 5.9555535038312275 minutes to train.\n",
      " - model saved to /data/site_id/final_models/model_site_15 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_file_path = \"/data/site_id/site_params.json\"\n",
    "with open(param_file_path, 'r') as f:\n",
    "    site_params = json.load(f)\n",
    "\n",
    "importance_threshold = 0.01\n",
    "\n",
    "for i in range(len(site_params.keys())):\n",
    "#for i in range(2):\n",
    "    \n",
    "    print(\"Attempting training with: site_{}\".format(i))\n",
    "    \n",
    "    # 1. Extract the parameters of each site\n",
    "    params = site_params[\"site_{}\".format(i)]\n",
    "    \n",
    "    # 2. Set the file/directory paths\n",
    "    site_train_file = site_id_train + \"/train_site_id_{}.csv\".format(i)\n",
    "    site_test_file = site_id_test + \"/test_site_id_{}.csv\".format(i)\n",
    "    feature_imp_file = site_id_feat_imp + \"/feat_imp_train_site_id_{}.csv\".format(i)\n",
    "    \n",
    "    model_save_path = site_id_models + \"model_site_{}\".format(i)\n",
    "    \n",
    "    # 3. Extract Important Features and Categorical Features\n",
    "    \n",
    "    imp_feats = pd.read_csv(feature_imp_file)\n",
    "    features_selected = set(imp_feats[imp_feats.Importances >= importance_threshold][\"Feature Id\"])\n",
    "\n",
    "    # Add meter_reading to the important features list\n",
    "    features_selected.add(\"meter_reading\")\n",
    "    \n",
    "    # Identify categorical features \n",
    "    cat_features_selected = list(features_selected.intersection(set(cat_features)))\n",
    "    \n",
    "    print(\" - imp features selected ... reading training files\")\n",
    "    # 4. Read the train file and create a train pool\n",
    "    train = pd.read_csv(site_train_file, index_col=0)[features_selected]\n",
    "    y_train = np.log1p(train.meter_reading)\n",
    "    X_train = train.drop([\"meter_reading\"], axis=1)\n",
    "    del train\n",
    "    \n",
    "    train_pool = create_catboost_pool(X_train, y_train, cat_features_selected)\n",
    "    del X_train, y_train\n",
    "    \n",
    "    # read the trest file and create test pool\n",
    "    test = pd.read_csv(site_test_file, index_col=0)[features_selected]\n",
    "    y_test = np.log1p(test.meter_reading)\n",
    "    X_test = test.drop(\"meter_reading\", axis=1)\n",
    "    del test\n",
    "    \n",
    "    test_pool = create_catboost_pool(X_test, y_test, cat_features_selected)\n",
    "    del X_test, y_test\n",
    "    \n",
    "    print(\" - pools created ... attempting training\")\n",
    "    # 5. Train the model\n",
    "    \n",
    "    iterations = params[\"iterations\"]\n",
    "    depth = params[\"depth\"]\n",
    "    learning_rate = params[\"learning_rate\"]\n",
    "    l2_leaf_reg = params[\"l2_leaf_reg\"]\n",
    "    \n",
    "    model = CatBoostRegressor(iterations= iterations,\n",
    "                              depth = depth,\n",
    "                              learning_rate=learning_rate,\n",
    "                              l2_leaf_reg=l2_leaf_reg,\n",
    "                              loss_function=\"RMSE\", \n",
    "                              boosting_type=\"Ordered\", \n",
    "                              eval_metric=\"MSLE\", \n",
    "                              od_type=\"Iter\", od_wait=100, \n",
    "                              use_best_model=True, \n",
    "                              verbose=100, \n",
    "                              random_seed=8848)\n",
    "    tic = time.time()\n",
    "    model.fit(train_pool, eval_set=test_pool)\n",
    "    toc = time.time()\n",
    "    print(\" - model fitted ...\")\n",
    "    print(\" - it took {} minutes to train.\".format((toc-tic)/60))\n",
    "    \n",
    "    # 6. Save the model\n",
    "    site_models[\"site_{}\".format(i)] = model\n",
    "    model.save_model(fname=model_save_path)\n",
    "    print(\" - model saved to {} \\n\".format(model_save_path))\n",
    "    \n",
    "    #del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost - Meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meter has been removed form the list below\n",
    "cat_features = [\n",
    "    \"site_id\",\n",
    "    'air_temperature_was_missing',\n",
    "     'building_id',\n",
    "     'cloud_coverage_was_missing',\n",
    "     'day_of_month',\n",
    "     'day_of_week',\n",
    "     'dew_temperature_was_missing',\n",
    "     'precip_depth_1_hr_was_missing',\n",
    "     'primary_use',\n",
    "     'sea_level_pressure_was_missing',\n",
    "     'site_idcloud_coverage_was_missing',\n",
    "     'wind_direction_was_missing',\n",
    "     'wind_speed_was_missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_train = \"/data/meter_type/train/\"\n",
    "meter_test = \"/data/meter_type/test/\"\n",
    "meter_feat_imp = \"/data/meter_type/imp_features/\"\n",
    "meter_models = \"/data/meter_type/final_models/\"\n",
    "\n",
    "meter_models_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting training with: meter_1\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.5579770\ttest: 0.5576534\tbest: 0.5576534 (0)\ttotal: 4.75s\tremaining: 39m 30s\n",
      "100:\tlearn: 0.3075246\ttest: 0.3013597\tbest: 0.3012434 (50)\ttotal: 4m 54s\tremaining: 19m 21s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.3012434134\n",
      "bestIteration = 50\n",
      "\n",
      "Shrink model to first 51 iterations.\n",
      " - model fitted ...\n",
      " - it took 5.793006602923075 minutes to train\n",
      " - model saved to /data/meter_type/final_models/model_meter_1\n",
      "\n",
      "\n",
      "Attempting training with: meter_2\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.5013716\ttest: 0.5010729\tbest: 0.5010729 (0)\ttotal: 2.74s\tremaining: 22m 45s\n",
      "100:\tlearn: 0.3164940\ttest: 0.3109665\tbest: 0.3109585 (93)\ttotal: 3m 7s\tremaining: 12m 21s\n",
      "200:\tlearn: 0.3164209\ttest: 0.3109219\tbest: 0.3109065 (170)\ttotal: 3m 46s\tremaining: 5m 37s\n",
      "300:\tlearn: 0.3163974\ttest: 0.3108733\tbest: 0.3108719 (286)\ttotal: 4m 32s\tremaining: 3m\n",
      "400:\tlearn: 0.3163075\ttest: 0.3103814\tbest: 0.3103747 (396)\ttotal: 5m 51s\tremaining: 1m 26s\n",
      "499:\tlearn: 0.3163473\ttest: 0.3103332\tbest: 0.3102673 (440)\ttotal: 8m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3102672628\n",
      "bestIteration = 440\n",
      "\n",
      "Shrink model to first 441 iterations.\n",
      " - model fitted ...\n",
      " - it took 8.412695729732514 minutes to train\n",
      " - model saved to /data/meter_type/final_models/model_meter_2\n",
      "\n",
      "\n",
      "Attempting training with: meter_3\n",
      " - imp features selected ... reading training files\n",
      " - pools created ... attempting training\n",
      "0:\tlearn: 0.7127756\ttest: 0.7092730\tbest: 0.7092730 (0)\ttotal: 1.98s\tremaining: 32m 57s\n",
      "100:\tlearn: 0.3894729\ttest: 0.3778719\tbest: 0.3778719 (100)\ttotal: 1m 44s\tremaining: 15m 26s\n",
      "200:\tlearn: 0.3862700\ttest: 0.3743492\tbest: 0.3743492 (200)\ttotal: 2m 33s\tremaining: 10m 8s\n",
      "300:\tlearn: 0.3835553\ttest: 0.3717579\tbest: 0.3717578 (299)\ttotal: 3m 11s\tremaining: 7m 24s\n",
      "400:\tlearn: 0.3738056\ttest: 0.3623609\tbest: 0.3623609 (400)\ttotal: 4m 24s\tremaining: 6m 34s\n",
      "500:\tlearn: 0.3709600\ttest: 0.3592737\tbest: 0.3592737 (500)\ttotal: 6m 40s\tremaining: 6m 39s\n",
      "600:\tlearn: 0.3696396\ttest: 0.3573998\tbest: 0.3573998 (600)\ttotal: 9m 6s\tremaining: 6m 3s\n",
      "700:\tlearn: 0.3688300\ttest: 0.3562481\tbest: 0.3561945 (678)\ttotal: 11m 29s\tremaining: 4m 53s\n",
      "800:\tlearn: 0.3683353\ttest: nan\tbest: 0.3560798 (718)\ttotal: 13m 44s\tremaining: 3m 24s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.3560797565\n",
      "bestIteration = 718\n",
      "\n",
      "Shrink model to first 719 iterations.\n",
      " - model fitted ...\n",
      " - it took 14.226030353705088 minutes to train\n",
      " - model saved to /data/meter_type/final_models/model_meter_3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_file_path = \"/data/meter_type/meter_params.json\"\n",
    "with open(param_file_path, 'r') as f:\n",
    "    meter_params = json.load(f)\n",
    "\n",
    "importance_threshold = 0.01\n",
    "\n",
    "#for i in range(len(meter_params.keys())):\n",
    "for i in [1, 2, 3]:\n",
    "    \n",
    "    print(\"Attempting training with: meter_{}\".format(i))\n",
    "    \n",
    "    # 1. Extract the parameters of each meter\n",
    "    params = meter_params[\"meter_{}\".format(i)]\n",
    "    \n",
    "    # 2. Set the file/directory paths\n",
    "    meter_train_file = meter_train + \"/train_meter_{}.csv\".format(i)\n",
    "    meter_test_file = meter_test + \"/test_meter_{}.csv\".format(i)\n",
    "    feature_imp_file = meter_feat_imp + \"/feat_imp_train_meter_{}.csv\".format(i)\n",
    "    \n",
    "    model_save_path = meter_models + \"model_meter_{}\".format(i)\n",
    "    \n",
    "    # 3. Extract Important Features and Categorical Features\n",
    "    \n",
    "    imp_feats = pd.read_csv(feature_imp_file)\n",
    "    features_selected = set(imp_feats[imp_feats.Importances >= importance_threshold][\"Feature Id\"])\n",
    "\n",
    "    # Add meter_reading to the important features list\n",
    "    features_selected.add(\"meter_reading\")\n",
    "    \n",
    "    # Identify categorical features \n",
    "    cat_features_selected = list(set(cat_features).intersection(set(features_selected)))\n",
    "    \n",
    "    print(\" - imp features selected ... reading training files\")\n",
    "    # 4. Read the train file and create a train pool\n",
    "    train = pd.read_csv(meter_train_file, index_col=0)[features_selected]\n",
    "    y_train = np.log1p(train.meter_reading)\n",
    "    X_train = train.drop([\"meter_reading\"], axis=1)\n",
    "    del train\n",
    "    gc.collect()\n",
    "    \n",
    "    train_pool = create_catboost_pool(X_train, y_train, cat_features_selected)\n",
    "    del X_train, y_train\n",
    "    \n",
    "    # read the trest file and create test pool\n",
    "    test = pd.read_csv(meter_test_file, index_col=0)[features_selected]\n",
    "    y_test = np.log1p(test.meter_reading)\n",
    "    X_test = test.drop(\"meter_reading\", axis=1)\n",
    "    del test\n",
    "    gc.collect()\n",
    "    \n",
    "    test_pool = create_catboost_pool(X_test, y_test, cat_features_selected)\n",
    "    del X_test, y_test\n",
    "    \n",
    "    print(\" - pools created ... attempting training\")\n",
    "    # 5. Train the model\n",
    "    \n",
    "    iterations = params[\"iterations\"]\n",
    "    depth = params[\"depth\"]\n",
    "    learning_rate = params[\"learning_rate\"]\n",
    "    l2_leaf_reg = params[\"l2_leaf_reg\"]\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=iterations,\n",
    "                              depth =depth,\n",
    "                              learning_rate=learning_rate,\n",
    "                              l2_leaf_reg=l2_leaf_reg,\n",
    "                              loss_function=\"RMSE\", \n",
    "                              boosting_type=\"Ordered\", \n",
    "                              eval_metric=\"MSLE\", \n",
    "                              od_type=\"Iter\", od_wait=100, \n",
    "                              use_best_model=True, \n",
    "                              verbose=100, \n",
    "                              random_seed=8848)\n",
    "    tic = time.time()\n",
    "    model.fit(train_pool, eval_set=test_pool)\n",
    "    toc = time.time()\n",
    "    print(\" - model fitted ...\")\n",
    "    print(\" - it took {} minutes to train\".format((toc-tic)/60))\n",
    "    \n",
    "    # 6. Save the model\n",
    "    meter_models_list[\"meter_{}\".format(i)] = model\n",
    "    model.save_model(fname=model_save_path)\n",
    "    print(\" - model saved to {}\\n\\n\".format(model_save_path))\n",
    "    \n",
    "    #del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
